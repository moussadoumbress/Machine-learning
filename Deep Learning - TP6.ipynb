{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Adversarial Networks (GAN)\n",
    "\n",
    "L'objectif de ce TP est de créer et manipuler un Generative Adversarial Networks (GAN) afin de générer des images de chiffres manuscrits à partir d'une base de données d'exemples.\n",
    "\n",
    "Vous aurez besoin des outils présents dans le fichier gan_tools_cuda.py que vous devrez copier dans votre répertoire Jupyter afin de pouvoir l'importer. Regardez bien les fonctions et classes définies dans ce fichier : il y a les codes permettant de télécharger la base de donnée d'images, de faire les conversions entre images et vecteurs, de générer les vecteurs de bruit à donner en entrée du générateur et de gérer l’affichage des résultats sous forme d'exemples d’images générées par le générateur et des indices de qualité du générateur et du discriminateur. \n",
    "\n",
    "###### 1. Importation des librairies et de gan_tools_cuda.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "import gan_tools_cuda as gt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Chargement des données d'apprentissage et création du \"loader\" \n",
    "\n",
    "Le loader présentera au réseau les données par paquet de 100, dans un ordre aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./torch_data/VGAN/MNIST/dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./torch_data/VGAN/MNIST/dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./torch_data/VGAN/MNIST/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./torch_data/VGAN/MNIST/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = gt.mnist_data()\n",
    "# Create loader with data, so that we can iterate over it\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n",
    "# Num batches\n",
    "num_batches = len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Création du discriminateur\n",
    "\n",
    "Créez une classe Python DiscriminatorNet décrivant la structure du réseau discriminateur. \n",
    "\n",
    "Le réseau est composé de trois couches cachées et d'une couche de sortie. Nous utiliserons le module \"séquentiel\" de Pytorch qui décrit l’ordre des différentes transformations à appliquer aux données dans chaque couche.\n",
    "\n",
    "L'entrée du réseau est un vecteur avec 784 valeurs (une image 28x28), la sortie est une valeur unique, allant de 0 (fausse image) à 1 (vraie image) grâce à l'utilisation d'une fonction sigmoïde.\n",
    "\n",
    "Les trois couches cachées utilisent une fonction LeakyReLU pour transformer leur sortie en valeurs quasi positives, avec alpha = 0,2. Elles utilisent également une fonction Dropout pour définir aléatoirement à zéro 30% des valeurs de sortie des neurones des couches cachées (il a été prouvé que cela augmentait les performances du réseau en empêchant le sur-apprentissage). Le nombre de neurones dans chaque couche cachée est respectivement de 1024, 512 et 256.\n",
    "\n",
    "La classe possède une méthode \"forward\" permettant de calculer la sortie du réseau à partir d'un vecteur d'entrée (représenaant une image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = 784\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(n_features, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "      \n",
    "        \"\"\" AUTRES COUCHES A COMPLETER \"\"\" \n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Linear(1024,512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2=nn.Sequential(\n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(256, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Création du générateur\n",
    "\n",
    "Créez une classe Python GeneratorNet décrivant la structure du réseau générateurs. Le réseau est composé de trois couches cachées et d'une couche de sortie. L'entrée du réseau est un vecteur avec 100 valeurs, la sortie est une image avec 784 valeurs (utilisez nn.Tanh() au lieu de nn.Sigmoid() pour convertir les valeurs de sortie). Les trois couches cachées utilisent une fonction LeakyReLU pour transformer leur sortie en valeurs quasi positives, avec alpha = 0,2, mais pas de Dropout ici. Le nombre de neurones dans chaque couche cachée est respectivement de 256, 512 et 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        \"\"\" A COMPLETER \"\"\" \n",
    "        self.hidden0=nn.Sequential(\n",
    "            nn.Linear(100,256),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1=nn.Sequential(\n",
    "            nn.Linear(256,512),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2=nn.Sequential(\n",
    "            nn.Linear(512,1024),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(1024,784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):   \n",
    "        \"\"\" A COMPLETER \"\"\"   \n",
    "        def forward(self, x):\n",
    "            x = self.hidden0(x)\n",
    "            x = self.hidden1(x)\n",
    "            x = self.hidden2(x)\n",
    "            x = self.out(x)\n",
    "            return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. Creation du processus d'apprentissage\n",
    "\n",
    "Initialisez les instances d'un discriminateur et d'un générateurs. Créez deux optimiseurs de type Adam pour les deux réseaux. Définissez la fonction de perte: ici, nous choisissons une fonction d'entropie croisée binaire pour vérifier si le discriminateur trouve la bonne réponse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = DiscriminatorNet()\n",
    "generator = GeneratorNet()\n",
    "if torch.cuda.is_available():\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()\n",
    "    \n",
    "# Optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créez une fonction train_generator et une fonction train_discriminator. \n",
    "Expliquez les différentes étapes du processus d'apprentissage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = loss(prediction_real, gt.real_data_target(real_data.size(0)))\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, gt.fake_data_target(real_data.size(0)))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error\n",
    "    return error_real + error_fake, prediction_real, prediction_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(optimizer, fake_data):\n",
    "    # 2. Train Generator\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error = loss(prediction, gt.real_data_target(prediction.size(0)))\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6. Apprentissage et visualisation:\n",
    "\n",
    "Pour chaque itération et pour chaque lot (\"batch\") de données, les étapes d'apprentissage sont les suivantes:\n",
    "\n",
    " - Transformez le lot de données en variables Torch à l'aide des fonctions Variable et gt.images_to_vectors. Ce sont les vraies données pour l'étape suivante.\n",
    "\n",
    " - Créez des vecteurs de bruit de taille 100 avec gt.noise (autant que de vraies images dans le lot), puis générez de fausses données avec le générateur.\n",
    "\n",
    " - Former le discriminateur sur les fausses données et les données réelles, en utilisant l'optimiseur défini ci-dessus (d_optimizer).\n",
    "\n",
    " - Créez d'autres vecteurs de bruit, taille 100, avec gt.noise.\n",
    "\n",
    " - Entrainez le générateur sur les vecteurs de bruit.\n",
    "\n",
    " - Visualisez un échantillon d'images générées avec gt.plot_gan. Cette fonction nécessite le numéro d'itération et de lot, ainsi que le nombre total de lots et le nom du générateur.\n",
    "\n",
    "###### Attention :\n",
    "Il se peut que le système se \"bloque\" dans une configuration où la sortie du générateur est la même quelle que soit l'entrée. Si toutes les images des exemples de sortie sont identiques après une dizaine d'itérations et que D(x) = 1 et D(G(z)) = 0, il faut relancer l'apprentissage (redémarrer le noyau)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    for n_batch, (real_batch,_) in enumerate(data_loader):\n",
    "\n",
    "        # 1 Train Discriminator\n",
    "        # 1.1 Prepare real data\n",
    "        real_data = Variable(gt.images_to_vectors(real_batch))\n",
    "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
    "            \n",
    "        # 1.2 Generate fake data with the Generator\n",
    "        \"\"\" A COMPLETER : Créer des vecteurs bruit \"\"\"\n",
    "        d_noise=torch.randn(real_data.shape)\n",
    "\n",
    "        \"\"\" A COMPLETER : Générer des images avec le générateur \"\"\"\n",
    "        generated=generator(real_data)\n",
    "        # 1.3 Train Discriminator \n",
    "        \"\"\" A COMPLETER : Entrainer le discriminateur \"\"\"\n",
    "        d_error=train_discriminator(d_optimizer,real_data,d_noise)\n",
    "        # 2 Train Generator\n",
    "        # 2.1 Generate noise\n",
    "        \"\"\"  A COMPLETER : Créer des vecteurs bruit à nouveau \"\"\"\n",
    "        g_noise=torch.randn(real_data.shape)              \n",
    "        # 2.2 Train Generator\n",
    "        \"\"\"  A COMPLETER : Entrainer le generateur \"\"\"\n",
    "        g_error=train_generator(g_optimizer,g_noise)                   \n",
    "        # Generate images from a fixed noise input and visualize the output\n",
    "        gt.plot_gan(epoch, n_batch, num_batches, generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 7. Exploration et optimisation\n",
    "\n",
    "Modifiez la structure des deux réseaux (discriminateur et générateur) en ajoutant ou enlevant des couches cachées, en modifiant le nombre de neurones dans ces couches et en jouant sur les paramètres des fonctions LeakyReLU et Dropout.\n",
    "\n",
    "Après avoir expliqué comment évaluer la qualité des images générées par le générateur, comparez la qualité des résultats obtenus avec les modifications que vous avez testé et essayez d’obtenir le meilleur résultat possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
