{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Self-Organizing Map (DeepSOM)\n",
    "\n",
    "L'objectif de ce TP est de créer et manipuler un Deep Self-Organizing Map (DeepSOM) afin d'apprendre une nouvelle représentation des données qui met en valeur leurs similarités.\n",
    "\n",
    "\n",
    "###### 1. Importation des librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Classe décrivant l'initialisation et l'apprentissage d'une SOM probabiliste\n",
    "\n",
    "Lisez attentivement ce code et vérifiez que vous ayez bien compris les différentes étapes de l'initialisation et de l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrSOM: # Une couche de SOM probabiliste\n",
    "    def __init__(self, data, shape):\n",
    "        self.shape = shape\n",
    "        self.N, self.dim = data.shape\n",
    "        self.data = data\n",
    "     \n",
    "        # Initialisation des prototypes selon les axes de l'ACP\n",
    "        self.pca = PCA().fit(self.data) \n",
    "        var = self.pca.transform(data).std(axis = 0)[0:2]\n",
    "        rangex = np.arange(-var[0],var[0],var[0]*2/self.shape[0])\n",
    "        if len(rangex)>self.shape[0]:\n",
    "            rangex = rangex[:-1]\n",
    "        rangey = np.arange(-var[1],var[1],var[1]*2/self.shape[1])\n",
    "        if len(rangey)>self.shape[1]:\n",
    "            rangey = rangey[:-1]  \n",
    "        self.W = []\n",
    "        for x in rangex:\n",
    "            for y in rangey:\n",
    "                self.W.append([x,y])\n",
    "        self.W = np.hstack((np.array(self.W), np.zeros((len(self.W),self.dim-2))))\n",
    "        self.W =self.pca.inverse_transform(self.W[:,:self.pca.components_.shape[0]])\n",
    "        if np.sum(self.data) == self.N:\n",
    "            self.W[self.W<0]=0\n",
    "        \n",
    "        # Initialization des temperatures (radius de voisinage)\n",
    "        self.s0 = max(1,max(self.shape)/4)\n",
    "        self.sf = 1\n",
    "        self.s = self.s0\n",
    "\n",
    "        # Initialization de beta\n",
    "        d = self.dist(self.W,self.W)\n",
    "        d[d==0] = 'NaN'\n",
    "        self.beta = 1/(np.max(np.nanmin(d,axis=0))**2)\n",
    "\n",
    "        # Nombre de neurones\n",
    "        self.nb_neuron = int(np.product(self.shape))        \n",
    "        \n",
    "        # Coordonnée des neurones\n",
    "        self.coord = []\n",
    "        for i in range(self.shape[0]):\n",
    "            for j in range(self.shape[1]):\n",
    "                self.coord.append([(i,j)])\n",
    "        \n",
    "        # Distance euclidienne entre les prototypes de la première couche\n",
    "        self.distmat = np.zeros((self.nb_neuron, self.nb_neuron))      \n",
    "        for n in range(self.nb_neuron):\n",
    "            for m in range(self.nb_neuron):\n",
    "                self.distmat[n,m] = euclidean(self.coord[n],self.coord[m])\n",
    "\n",
    "        # Initialization de la matrice P de probabilité entre chaque donnée et chaque neurone\n",
    "        self.P = np.zeros((self.N, self.nb_neuron))+1/self.nb_neuron\n",
    "        \n",
    "        # Initialization de la matrice q de probabilité à priori pour chaque neurone\n",
    "        self.q = np.zeros(self.nb_neuron)+1/self.nb_neuron\n",
    "        \n",
    "     \n",
    "    def Kij(self, T): # Calcul de la fonction de voisinage\n",
    "        self.s = self.s0*(self.sf/self.s0)**(T/self.Tmax)\n",
    "        \n",
    "        if self.s>0:\n",
    "            return np.exp(-self.distmat**2/(2*self.s**2))\n",
    "        else:\n",
    "            return np.identity(self.nb_neuron)\n",
    "        \n",
    "        \n",
    "    def train(self,Tmax): #Apprentissage\n",
    "        self.Tmax = Tmax\n",
    "        \n",
    "        for T in range(Tmax):\n",
    "            # Calcul de K, la fonction de voisinage\n",
    "            self.K = self.Kij(T)\n",
    "            \n",
    "            # Affectation des données aux neurones (calcul de P)\n",
    "            self.assign(self.data)\n",
    "            \n",
    "            # Mise à jours de prototypes (calcul de W)\n",
    "            self.update()\n",
    "\n",
    "    \n",
    "    def dist(self, X1, X2):  # Calcul des distances \n",
    "        if np.sum(self.data) == self.N:\n",
    "            return 1/np.sqrt(2)*euclidean_distances(np.sqrt(X1), np.sqrt(X2)) ## Hellinger pour probabilités\n",
    "        else:\n",
    "            return euclidean_distances(X1, X2)  ## Euclidienne pour vecteurs (première couche)\n",
    "            \n",
    "        \n",
    "    def assign(self, X):  ## Calcul de la matrice P de probabilité entre chaque donnée et chaque neurone \n",
    "        # Distance entre les données et les prototypes\n",
    "        self.Dxw = 1/2*self.dist(X, self.W)**2\n",
    "        \n",
    "        # Création de la matrice Q\n",
    "        Q = np.tile(self.q,(self.N,1)).T \n",
    "        \n",
    "        # Calcul de P\n",
    "        self.P = Q * np.dot(self.K,np.exp(-self.beta*self.Dxw.T)) \n",
    "        norm = np.tile(np.sum(self.P, axis=0),(self.nb_neuron,1))+1e-16\n",
    "        self.P = self.P / norm       \n",
    "        \n",
    "        return self.P\n",
    "\n",
    "\n",
    "    def update(self): ## Calcul de W, la matrice des prototypes\n",
    "        # Calcul de P * K\n",
    "        KP = np.dot(self.K,self.P)\n",
    "    \n",
    "        #calcul de W\n",
    "        norm = np.tile(np.sum(KP, axis=1),(self.dim,1)).T\n",
    "        self.W = np.dot(KP,self.data) / norm\n",
    "    \n",
    "    \n",
    "    def Poutput(self): # Calcul et mise en forme de la sortie des couches\n",
    "    \n",
    "        mask = self.shape\n",
    "        P = self.assign(self.data).T\n",
    "        self.out = []\n",
    "\n",
    "        for p in P:\n",
    "            pmat = p.reshape(mask)                            \n",
    "            self.out.append(pmat.reshape((1,mask[0]*mask[1]))[0])\n",
    "            \n",
    "        self.out = np.array(self.out)\n",
    "        \n",
    "        return (self.out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Classe décrivant l'initialisation et l'apprentissage de DeepSOM\n",
    "\n",
    "Créez une classe permettant l'apprentissage de toutes les couches de la DeepSOM à partir d'un ensemble de données d'apprentissage.\n",
    "\n",
    "Faites attention aux points suivants :\n",
    " - Il faut définit les dimentions (shape) de la carte de la première couche.\n",
    " - La taille de la carte diminue de 2 lignes et 2 colonnes pour chaque couche sucessive, avec des dimientions minimale de 4x4.\n",
    " - L'apprentisage prends comme argument un nombre d'itérations.\n",
    " - Les differentes couches sont stockées dans une liste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSOM:\n",
    "    def __init__(self, data, N_layers, shape):\n",
    "        self.data = data\n",
    "        self.N_layers = N_layers\n",
    "        self.shape = shape\n",
    "        self.out = []    # initialisation de la sortie\n",
    "    \n",
    "    \n",
    "    def train(self, Tmax):\n",
    "        X = self.data\n",
    "        self.layers = [] #liste des couches\n",
    "        \n",
    "        # Pour chaque couche :\n",
    "        for i in range(self.N_layers): \n",
    "            \n",
    "            # Mise à jour la taille de la carte \n",
    "            \"\"\" A COMPLETER \"\"\"\n",
    "            \n",
    "            # Initialisation de la couche\n",
    "            \"\"\" A COMPLETER \"\"\"\n",
    "            \n",
    "            # Apprentissage de la couche\n",
    "            \"\"\" A COMPLETER \"\"\"\n",
    "            \n",
    "            # Calcul de la sortie de la couche\n",
    "            \"\"\" A COMPLETER \"\"\"\n",
    "            \n",
    "            # Mise en mémoire de la couche\n",
    "            \"\"\" A COMPLETER \"\"\"\n",
    "        \n",
    "        self.out = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Application de la DeepSOM sur des jeux de données \n",
    "\n",
    " 1. Chargez des données en utilisant 'dataset' de la librairie sklearn (par exemple les données 'iris'). \n",
    " 2. Lancez l'apprentissage de DeepSOM sur ces données.\n",
    " 3. Affichez le score de chaque couche, défini comme la moyenne du rapport entre la plus petite et la plus grande distance de chaque donnée avec les autres données ( => mean(dist_min/dist_max)). Vérifiez que le score décroît de la première couche à la dernière.\n",
    " 4. Visualisez la sortie du réseau avec 'imshow', avec triant les données selon leurs classes; afin de vérifier que les données d'une même classe ont une représentation identique. Utilisez une \n",
    " \n",
    "Testez l'algorithme sur différents jeux de données, en faisant varier les paramètres (nombre de couches, dimensions de la carte de la première couche) afin d'obtenir les meilleurs résultats.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b0b7dda8e848>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Création et apprentissage de la DeepSOM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;34m\"\"\" A COMPLETER \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepSOM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;34m\"\"\" A COMPLETER \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "# Chargement des données\n",
    "\"\"\" A COMPLETER \"\"\"\n",
    "\n",
    "# Création et apprentissage de la DeepSOM\n",
    "\"\"\" A COMPLETER \"\"\"\n",
    "shape = (a,b)\n",
    "S = DeepSOM(data, nb_layers, shape)\n",
    "\"\"\" A COMPLETER \"\"\"\n",
    "\n",
    "# Affichage des scores Ijs pour chaque couche\n",
    "l=0\n",
    "for lay in S.layers:\n",
    "    l+=1\n",
    "    \n",
    "    \"\"\" A COMPLETER \"\"\"\n",
    "\n",
    "    index = np.mean(mi/ma)\n",
    "    print(\"Couche \",l,\": score = \", round(index,3))\n",
    "\n",
    "# Visualisation des représentations des données en sortie du réseau\n",
    "\"\"\" A COMPLETER \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
